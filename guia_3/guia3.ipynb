{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Using cached openai-2.6.1-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai)\n",
      "  Using cached anyio-4.11.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.10.0 (from openai)\n",
      "  Using cached jiter-0.11.1-cp311-cp311-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Using cached pydantic-2.12.3-py3-none-any.whl.metadata (87 kB)\n",
      "Collecting sniffio (from openai)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>4 (from openai)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\jaider.vargas-n\\downloads\\hello-openai\\guia_3\\.venv\\lib\\site-packages (from openai) (4.15.0)\n",
      "Collecting idna>=2.8 (from anyio<5,>=3.5.0->openai)\n",
      "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting certifi (from httpx<1,>=0.23.0->openai)\n",
      "  Using cached certifi-2025.10.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.4 (from pydantic<3,>=1.9.0->openai)\n",
      "  Using cached pydantic_core-2.41.4-cp311-cp311-win_amd64.whl.metadata (7.4 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic<3,>=1.9.0->openai)\n",
      "  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\jaider.vargas-n\\downloads\\hello-openai\\guia_3\\.venv\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Using cached openai-2.6.1-py3-none-any.whl (1.0 MB)\n",
      "Using cached anyio-4.11.0-py3-none-any.whl (109 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Using cached jiter-0.11.1-cp311-cp311-win_amd64.whl (207 kB)\n",
      "Using cached pydantic-2.12.3-py3-none-any.whl (462 kB)\n",
      "Using cached pydantic_core-2.41.4-cp311-cp311-win_amd64.whl (2.0 MB)\n",
      "Using cached python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Using cached certifi-2025.10.5-py3-none-any.whl (163 kB)\n",
      "Installing collected packages: typing-inspection, tqdm, sniffio, python-dotenv, pydantic-core, jiter, idna, h11, distro, certifi, annotated-types, pydantic, httpcore, anyio, httpx, openai\n",
      "\n",
      "   -- -------------------------------------  1/16 [tqdm]\n",
      "   -- -------------------------------------  1/16 [tqdm]\n",
      "   ----- ----------------------------------  2/16 [sniffio]\n",
      "   ------- --------------------------------  3/16 [python-dotenv]\n",
      "   --------------- ------------------------  6/16 [idna]\n",
      "   ----------------- ----------------------  7/16 [h11]\n",
      "   -------------------- -------------------  8/16 [distro]\n",
      "   ------------------------- -------------- 10/16 [annotated-types]\n",
      "   --------------------------- ------------ 11/16 [pydantic]\n",
      "   --------------------------- ------------ 11/16 [pydantic]\n",
      "   --------------------------- ------------ 11/16 [pydantic]\n",
      "   --------------------------- ------------ 11/16 [pydantic]\n",
      "   --------------------------- ------------ 11/16 [pydantic]\n",
      "   --------------------------- ------------ 11/16 [pydantic]\n",
      "   --------------------------- ------------ 11/16 [pydantic]\n",
      "   --------------------------- ------------ 11/16 [pydantic]\n",
      "   ------------------------------ --------- 12/16 [httpcore]\n",
      "   ------------------------------ --------- 12/16 [httpcore]\n",
      "   -------------------------------- ------- 13/16 [anyio]\n",
      "   -------------------------------- ------- 13/16 [anyio]\n",
      "   -------------------------------- ------- 13/16 [anyio]\n",
      "   ----------------------------------- ---- 14/16 [httpx]\n",
      "   ----------------------------------- ---- 14/16 [httpx]\n",
      "   ----------------------------------- ---- 14/16 [httpx]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ------------------------------------- -- 15/16 [openai]\n",
      "   ---------------------------------------- 16/16 [openai]\n",
      "\n",
      "Successfully installed annotated-types-0.7.0 anyio-4.11.0 certifi-2025.10.5 distro-1.9.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 idna-3.11 jiter-0.11.1 openai-2.6.1 pydantic-2.12.3 pydantic-core-2.41.4 python-dotenv-1.2.1 sniffio-1.3.1 tqdm-4.67.1 typing-inspection-0.4.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai python-dotenv \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cliente inicializado. Modelo listo para consultas.\n"
     ]
    }
   ],
   "source": [
    "# 3) Cargar la clave y crear el cliente\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv()  # Lee el archivo .env\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "print(\"Cliente inicializado. Modelo listo para consultas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La inteligencia artificial en la educación se refiere al uso de tecnologías y algoritmos que permiten personalizar y optimizar el aprendizaje, adaptándose a las necesidades y ritmos de cada estudiante. Estas herramientas pueden incluir sistemas de tutoría inteligente, análisis de datos para mejorar la enseñanza y recursos educativos interactivos que fomentan un aprendizaje más efectivo y accesible.\n"
     ]
    }
   ],
   "source": [
    "# 5) Primera consulta: respuesta libre\n",
    "prompt = \"Explica en dos frases qué es la inteligencia artificial en la educación.\"\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    temperature=0.7  # más creativo que 0.2, menos que 1.0\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"operation\": \"explanation\",\n",
      "  \"input\": \"¿Qué es aprendizaje supervisado?\",\n",
      "  \"output\": \"El aprendizaje supervisado es un tipo de aprendizaje automático donde un modelo es entrenado utilizando un conjunto de datos etiquetados. Esto significa que cada entrada del conjunto de datos tiene una salida conocida, lo que permite al modelo aprender a predecir resultados a partir de nuevas entradas. Se utiliza comúnmente en tareas como clasificación y regresión.\"\n",
      "}\n",
      "\n",
      "Valid JSON → {'operation': 'explanation', 'input': '¿Qué es aprendizaje supervisado?', 'output': 'El aprendizaje supervisado es un tipo de aprendizaje automático donde un modelo es entrenado utilizando un conjunto de datos etiquetados. Esto significa que cada entrada del conjunto de datos tiene una salida conocida, lo que permite al modelo aprender a predecir resultados a partir de nuevas entradas. Se utiliza comúnmente en tareas como clasificación y regresión.'}\n"
     ]
    }
   ],
   "source": [
    "# 6) Respuesta estructurada en JSON para automatización\n",
    "import json\n",
    "\n",
    "query = \"¿Qué es aprendizaje supervisado?\"\n",
    "schema_instruction = (\n",
    "    \"Responde en formato JSON con las claves: operation, input, output. \"\n",
    "    \"operation debe ser 'explanation'; input debe repetir la pregunta; output la explicación clara y breve.\"\n",
    ")\n",
    "response_json = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": schema_instruction},\n",
    "        {\"role\": \"user\", \"content\": query}\n",
    "    ],\n",
    "    temperature=0.3,       # más determinista para formatos estructurados\n",
    "    max_tokens=300         # suficiente para una explicación breve\n",
    ")\n",
    "text = response_json.choices[0].message.content\n",
    "print(text)\n",
    "\n",
    "# (Opcional) intentar cargar como JSON si el modelo devolvió un objeto válido\n",
    "try:\n",
    "    data = json.loads(text)\n",
    "    print(\"\\nValid JSON →\", data)\n",
    "except json.JSONDecodeError:\n",
    "    print(\"\\nLa salida no es JSON válido literal. Puedes parsearla manualmente o usar validadores/funciones JSON del proveedor.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Ejercicios propuestos\n",
    "1. Cambia `temperature` a 0.1, 0.5 y 0.9 y compara el estilo de las respuestas.\n",
    "2. Pide que el modelo responda **siempre en JSON** usando un `system` que lo exija. Verifica si cumple.\n",
    "3. Crea un prompt de tu área (p.ej., *programación*, *arquitectura*, *matemáticas*) que devuelva un JSON con `operation`, `input`, `steps` (lista) y `output`.\n",
    "4. Limita la longitud con `max_tokens` y observa si corta.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"prompt\": \"Explica brevemente el principio de funcionamiento de un árbol de decisión.\",\n",
      "  \"respuesta\": \"Un árbol de decisión es un modelo de aprendizaje automático que utiliza una estructura jerárquica para tomar decisiones basadas en características de los datos. Cada nodo interno representa una prueba sobre un atributo, cada rama representa el resultado de la prueba y cada hoja representa una clase o resultado final, permitiendo clasificar o predecir resultados a partir de nuevas entradas.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Plantilla reutilizable para el curso\n",
    "def ask_model(prompt: str,\n",
    "              model: str = \"gpt-4o-mini\",\n",
    "              temperature: float = 0.1,\n",
    "              max_tokens: int = 400,\n",
    "              system: str | None = None):\n",
    "    messages = []\n",
    "    if system:\n",
    "        messages.append({\"role\": \"system\", \"content\": system})\n",
    "    messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "    resp = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens\n",
    "    )\n",
    "    return resp.choices[0].message.content\n",
    "\n",
    "# Ejemplo de uso\n",
    "print(ask_model(\n",
    "    \"Explica brevemente el principio de funcionamiento de un árbol de decisión.\",\n",
    "    temperature=0.4,\n",
    "    system=\"Responde en dos oraciones, tono docente y preciso. Siempre responde JSON con llaves promt y respuesta\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"prompt\": \"Explica brevemente el principio de funcionamiento de un árbol de decisión.\",\n",
      "  \"respuesta\": \"Un árbol de decisión es un modelo de aprendizaje automático que utiliza una estructura jerárquica para tomar decisiones basadas en características de los datos. Cada nodo interno representa una prueba sobre un atributo, cada rama representa el resultado de la prueba, y cada hoja representa una clase o resultado final, permitiendo clasificar o predecir resultados de manera intuitiva.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Plantilla reutilizable para el curso\n",
    "def ask_model(prompt: str,\n",
    "              model: str = \"gpt-4o-mini\",\n",
    "              temperature: float = 0.5,\n",
    "              max_tokens: int = 400,\n",
    "              system: str | None = None):\n",
    "    messages = []\n",
    "    if system:\n",
    "        messages.append({\"role\": \"system\", \"content\": system})\n",
    "    messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "    resp = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens\n",
    "    )\n",
    "    return resp.choices[0].message.content\n",
    "\n",
    "# Ejemplo de uso\n",
    "print(ask_model(\n",
    "    \"Explica brevemente el principio de funcionamiento de un árbol de decisión.\",\n",
    "    temperature=0.4,\n",
    "    system=\"Responde en dos oraciones, tono docente y preciso. Siempre responde JSON con llaves promt y respuesta\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"promt\": \"Explica brevemente el principio de funcionamiento de un árbol de decisión.\",\n",
      "  \"respuesta\": \"Un árbol de decisión es un modelo de aprendizaje automático que utiliza una estructura en forma de árbol para tomar decisiones basadas en características de entrada. Cada nodo interno representa una prueba sobre una característica, cada rama representa el resultado de esa prueba, y cada hoja representa una decisión final o clasificación.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Plantilla reutilizable para el curso\n",
    "def ask_model(prompt: str,\n",
    "              model: str = \"gpt-4o-mini\",\n",
    "              temperature: float = 0.9,\n",
    "              max_tokens: int = 400,\n",
    "              system: str | None = None):\n",
    "    messages = []\n",
    "    if system:\n",
    "        messages.append({\"role\": \"system\", \"content\": system})\n",
    "    messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "    resp = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens\n",
    "    )\n",
    "    return resp.choices[0].message.content\n",
    "\n",
    "# Ejemplo de uso\n",
    "print(ask_model(\n",
    "    \"Explica brevemente el principio de funcionamiento de un árbol de decisión.\",\n",
    "    temperature=0.4,\n",
    "    system=\"Responde en dos oraciones, tono docente y preciso. Siempre responde JSON con llaves promt y respuesta\"\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al ir aumentando el temperautre, la salida se va volviendo creativa"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

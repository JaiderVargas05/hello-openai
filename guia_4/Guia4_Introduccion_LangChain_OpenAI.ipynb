{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83152e03",
   "metadata": {},
   "source": [
    "# Guía 3 — Introducción a LangChain con OpenAI API\n",
    "Curso: **IA en el Aula — Nivel Avanzado**  \n",
    "Profesor: **Luis Daniel Benavides Navarro**  \n",
    "Fecha: **Octubre 2025**\n",
    "\n",
    "En esta guía aprenderás los conceptos básicos de **LangChain**, una librería diseñada para construir aplicaciones impulsadas por modelos de lenguaje, integrando la API de OpenAI con flujos más complejos. Exploraremos cómo crear un primer **prompt chain**, administrar memoria y usar herramientas para componer respuestas inteligentes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4929bd",
   "metadata": {},
   "source": [
    "## 1️⃣ Instalación y configuración inicial\n",
    "LangChain se instala como cualquier otra librería de Python. También usaremos `python-dotenv` para gestionar la clave de OpenAI. Ejecute la siguiente celda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aca0e6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\jaider.vargas-n\\downloads\\hello-openai\\guia_3\\.venv\\lib\\site-packages (2.6.1)\n",
      "Collecting langchain\n",
      "  Downloading langchain-1.0.2-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\jaider.vargas-n\\downloads\\hello-openai\\guia_3\\.venv\\lib\\site-packages (1.2.1)\n",
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-1.0.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\jaider.vargas-n\\downloads\\hello-openai\\guia_3\\.venv\\lib\\site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\jaider.vargas-n\\downloads\\hello-openai\\guia_3\\.venv\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\jaider.vargas-n\\downloads\\hello-openai\\guia_3\\.venv\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\jaider.vargas-n\\downloads\\hello-openai\\guia_3\\.venv\\lib\\site-packages (from openai) (0.11.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\jaider.vargas-n\\downloads\\hello-openai\\guia_3\\.venv\\lib\\site-packages (from openai) (2.12.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\jaider.vargas-n\\downloads\\hello-openai\\guia_3\\.venv\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\jaider.vargas-n\\downloads\\hello-openai\\guia_3\\.venv\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\jaider.vargas-n\\downloads\\hello-openai\\guia_3\\.venv\\lib\\site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\jaider.vargas-n\\downloads\\hello-openai\\guia_3\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
      "Requirement already satisfied: certifi in c:\\users\\jaider.vargas-n\\downloads\\hello-openai\\guia_3\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\jaider.vargas-n\\downloads\\hello-openai\\guia_3\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\jaider.vargas-n\\downloads\\hello-openai\\guia_3\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\jaider.vargas-n\\downloads\\hello-openai\\guia_3\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in c:\\users\\jaider.vargas-n\\downloads\\hello-openai\\guia_3\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\jaider.vargas-n\\downloads\\hello-openai\\guia_3\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
      "Collecting langchain-core<2.0.0,>=1.0.0 (from langchain)\n",
      "  Downloading langchain_core-1.0.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting langgraph<1.1.0,>=1.0.0 (from langchain)\n",
      "  Downloading langgraph-1.0.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting jsonpatch<2.0.0,>=1.33.0 (from langchain-core<2.0.0,>=1.0.0->langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langsmith<1.0.0,>=0.3.45 (from langchain-core<2.0.0,>=1.0.0->langchain)\n",
      "  Downloading langsmith-0.4.38-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\jaider.vargas-n\\downloads\\hello-openai\\guia_3\\.venv\\lib\\site-packages (from langchain-core<2.0.0,>=1.0.0->langchain) (25.0)\n",
      "Collecting pyyaml<7.0.0,>=5.3.0 (from langchain-core<2.0.0,>=1.0.0->langchain)\n",
      "  Using cached pyyaml-6.0.3-cp311-cp311-win_amd64.whl.metadata (2.4 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<2.0.0,>=1.0.0->langchain)\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langgraph-checkpoint<4.0.0,>=2.1.0 (from langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Downloading langgraph_checkpoint-3.0.0-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting langgraph-prebuilt<1.1.0,>=1.0.0 (from langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Downloading langgraph_prebuilt-1.0.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Downloading langgraph_sdk-0.2.9-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting xxhash>=3.5.0 (from langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Downloading xxhash-3.6.0-cp311-cp311-win_amd64.whl.metadata (13 kB)\n",
      "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Downloading ormsgpack-1.11.0-cp311-cp311-win_amd64.whl.metadata (1.2 kB)\n",
      "Collecting orjson>=3.10.1 (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.0->langchain)\n",
      "  Downloading orjson-3.11.4-cp311-cp311-win_amd64.whl.metadata (42 kB)\n",
      "Collecting requests-toolbelt>=1.0.0 (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting requests>=2.0.0 (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting zstandard>=0.23.0 (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain)\n",
      "  Downloading zstandard-0.25.0-cp311-cp311-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting tiktoken<1.0.0,>=0.7.0 (from langchain-openai)\n",
      "  Downloading tiktoken-0.12.0-cp311-cp311-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1.0.0,>=0.7.0->langchain-openai)\n",
      "  Downloading regex-2025.10.23-cp311-cp311-win_amd64.whl.metadata (41 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain)\n",
      "  Using cached charset_normalizer-3.4.4-cp311-cp311-win_amd64.whl.metadata (38 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\jaider.vargas-n\\downloads\\hello-openai\\guia_3\\.venv\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Downloading langchain-1.0.2-py3-none-any.whl (107 kB)\n",
      "Downloading langchain_core-1.0.1-py3-none-any.whl (467 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langgraph-1.0.1-py3-none-any.whl (155 kB)\n",
      "Downloading langgraph_checkpoint-3.0.0-py3-none-any.whl (46 kB)\n",
      "Downloading langgraph_prebuilt-1.0.1-py3-none-any.whl (28 kB)\n",
      "Downloading langgraph_sdk-0.2.9-py3-none-any.whl (56 kB)\n",
      "Downloading langsmith-0.4.38-py3-none-any.whl (397 kB)\n",
      "Using cached pyyaml-6.0.3-cp311-cp311-win_amd64.whl (158 kB)\n",
      "Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading langchain_openai-1.0.1-py3-none-any.whl (81 kB)\n",
      "Downloading tiktoken-0.12.0-cp311-cp311-win_amd64.whl (879 kB)\n",
      "   ---------------------------------------- 0.0/879.4 kB ? eta -:--:--\n",
      "   ----------------------- ---------------- 524.3/879.4 kB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 879.4/879.4 kB 3.6 MB/s  0:00:00\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading orjson-3.11.4-cp311-cp311-win_amd64.whl (131 kB)\n",
      "Downloading ormsgpack-1.11.0-cp311-cp311-win_amd64.whl (112 kB)\n",
      "Downloading regex-2025.10.23-cp311-cp311-win_amd64.whl (277 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.4-cp311-cp311-win_amd64.whl (106 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading xxhash-3.6.0-cp311-cp311-win_amd64.whl (31 kB)\n",
      "Downloading zstandard-0.25.0-cp311-cp311-win_amd64.whl (506 kB)\n",
      "Installing collected packages: zstandard, xxhash, urllib3, tenacity, regex, pyyaml, ormsgpack, orjson, jsonpointer, charset_normalizer, requests, jsonpatch, tiktoken, requests-toolbelt, langgraph-sdk, langsmith, langchain-core, langgraph-checkpoint, langchain-openai, langgraph-prebuilt, langgraph, langchain\n",
      "\n",
      "   --- ------------------------------------  2/22 [urllib3]\n",
      "   --- ------------------------------------  2/22 [urllib3]\n",
      "   --- ------------------------------------  2/22 [urllib3]\n",
      "   ----- ----------------------------------  3/22 [tenacity]\n",
      "   ------- --------------------------------  4/22 [regex]\n",
      "   ------- --------------------------------  4/22 [regex]\n",
      "   --------- ------------------------------  5/22 [pyyaml]\n",
      "   ---------------- -----------------------  9/22 [charset_normalizer]\n",
      "   ---------------- -----------------------  9/22 [charset_normalizer]\n",
      "   ------------------ --------------------- 10/22 [requests]\n",
      "   ------------------ --------------------- 10/22 [requests]\n",
      "   --------------------- ------------------ 12/22 [tiktoken]\n",
      "   ----------------------- ---------------- 13/22 [requests-toolbelt]\n",
      "   ----------------------- ---------------- 13/22 [requests-toolbelt]\n",
      "   ------------------------- -------------- 14/22 [langgraph-sdk]\n",
      "   --------------------------- ------------ 15/22 [langsmith]\n",
      "   --------------------------- ------------ 15/22 [langsmith]\n",
      "   --------------------------- ------------ 15/22 [langsmith]\n",
      "   --------------------------- ------------ 15/22 [langsmith]\n",
      "   --------------------------- ------------ 15/22 [langsmith]\n",
      "   --------------------------- ------------ 15/22 [langsmith]\n",
      "   ----------------------------- ---------- 16/22 [langchain-core]\n",
      "   ----------------------------- ---------- 16/22 [langchain-core]\n",
      "   ----------------------------- ---------- 16/22 [langchain-core]\n",
      "   ----------------------------- ---------- 16/22 [langchain-core]\n",
      "   ----------------------------- ---------- 16/22 [langchain-core]\n",
      "   ----------------------------- ---------- 16/22 [langchain-core]\n",
      "   ----------------------------- ---------- 16/22 [langchain-core]\n",
      "   ----------------------------- ---------- 16/22 [langchain-core]\n",
      "   ----------------------------- ---------- 16/22 [langchain-core]\n",
      "   ----------------------------- ---------- 16/22 [langchain-core]\n",
      "   ----------------------------- ---------- 16/22 [langchain-core]\n",
      "   ----------------------------- ---------- 16/22 [langchain-core]\n",
      "   ----------------------------- ---------- 16/22 [langchain-core]\n",
      "   ----------------------------- ---------- 16/22 [langchain-core]\n",
      "   ------------------------------ --------- 17/22 [langgraph-checkpoint]\n",
      "   ------------------------------ --------- 17/22 [langgraph-checkpoint]\n",
      "   -------------------------------- ------- 18/22 [langchain-openai]\n",
      "   ------------------------------------ --- 20/22 [langgraph]\n",
      "   ------------------------------------ --- 20/22 [langgraph]\n",
      "   ------------------------------------ --- 20/22 [langgraph]\n",
      "   ------------------------------------ --- 20/22 [langgraph]\n",
      "   ------------------------------------ --- 20/22 [langgraph]\n",
      "   ------------------------------------ --- 20/22 [langgraph]\n",
      "   -------------------------------------- - 21/22 [langchain]\n",
      "   -------------------------------------- - 21/22 [langchain]\n",
      "   -------------------------------------- - 21/22 [langchain]\n",
      "   ---------------------------------------- 22/22 [langchain]\n",
      "\n",
      "Successfully installed charset_normalizer-3.4.4 jsonpatch-1.33 jsonpointer-3.0.0 langchain-1.0.2 langchain-core-1.0.1 langchain-openai-1.0.1 langgraph-1.0.1 langgraph-checkpoint-3.0.0 langgraph-prebuilt-1.0.1 langgraph-sdk-0.2.9 langsmith-0.4.38 orjson-3.11.4 ormsgpack-1.11.0 pyyaml-6.0.3 regex-2025.10.23 requests-2.32.5 requests-toolbelt-1.0.0 tenacity-9.1.2 tiktoken-0.12.0 urllib3-2.5.0 xxhash-3.6.0 zstandard-0.25.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai langchain python-dotenv langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aee39b5",
   "metadata": {},
   "source": [
    "## 2️⃣ Cargar variables de entorno y cliente OpenAI\n",
    "Crea un archivo `.env` con tu clave de API y cárgala para poder usarla dentro de LangChain. Esto evita exponer tu clave en el código fuente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b3fcb82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cliente LangChain con OpenAI inicializado correctamente.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "load_dotenv()  # Cargar archivo .env\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not api_key:\n",
    "    raise ValueError(\"No se encontró la clave OPENAI_API_KEY en el archivo .env\")\n",
    "\n",
    "# Crear cliente LangChain con OpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5)\n",
    "print(\"Cliente LangChain con OpenAI inicializado correctamente.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e2926d",
   "metadata": {},
   "source": [
    "## 3️⃣ Primer ejemplo: Prompt simple con LangChain\n",
    "LangChain utiliza **chains** (cadenas de pasos) para procesar información. Comencemos con una cadena simple que envía un mensaje al modelo y obtiene la respuesta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0769dbb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El aprendizaje automático es una rama de la inteligencia artificial que permite a las computadoras aprender y mejorar su rendimiento en tareas específicas a partir de datos, sin ser programadas explícitamente para cada tarea. Utiliza algoritmos y modelos estadísticos para identificar patrones y hacer predicciones basadas en la información disponible.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Initialize the LLM (uses your OpenAI API key from environment)\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5)\n",
    "\n",
    "# Create a simple prompt\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Explica en dos frases el concepto de {tema}.\"\n",
    ")\n",
    "\n",
    "# Combine the components using LCEL (LangChain Expression Language)\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# Run it\n",
    "result = chain.invoke({\"tema\": \"aprendizaje automático\"})\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5349f8b",
   "metadata": {},
   "source": [
    "### Explicación\n",
    "- **ChatPromptTemplate:** define la estructura del mensaje que se envía al modelo.\n",
    "- **ChatOpenAI:** la conexión real al modelo.\n",
    "- **chain** crea la cadena de componentes usando LCEL (LangChain Expression Language).\n",
    "- **StrOutputParser** convierte la salida estructurada del modelo en texto plano.\n",
    "- **chain.invoke:** ejecuta la cadena pasando los valores del prompt.\n",
    "\n",
    "Este patrón permite reutilizar prompts para distintos temas o contextos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6939352f",
   "metadata": {},
   "source": [
    "## 4️⃣ Ejemplo 2: Encadenar múltiples pasos\n",
    "LangChain permite combinar varios pasos en una misma ejecución. En este ejemplo, crearemos dos prompts: uno para definir un tema y otro para generar una aplicación educativa basada en el resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6cd03c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Aplicación Educativa: \"ExplorAR\"\n",
      "\n",
      "**Descripción General:**\n",
      "\"ExplorAR\" es una aplicación educativa de realidad aumentada diseñada para enriquecer el aprendizaje en diversas materias, como ciencias, historia, geografía y arte. La aplicación permite a los estudiantes interactuar con contenidos digitales superpuestos en su entorno físico, facilitando una comprensión más profunda y contextualizada de los temas que están estudiando.\n",
      "\n",
      "**Características de la Aplicación:**\n",
      "\n",
      "1. **Exploración Interactiva:**\n",
      "   - Los estudiantes pueden escanear objetos o lugares específicos (por ejemplo, un libro de texto, un mapa o un modelo físico) con su dispositivo móvil. La aplicación reconocerá el objeto y mostrará información adicional, como videos, infografías o animaciones en 3D que explican conceptos relacionados.\n",
      "\n",
      "2. **Lecciones de Campo Virtuales:**\n",
      "   - \"ExplorAR\" permite a los docentes crear lecciones de campo virtuales. Por ejemplo, al visitar un sitio histórico, los estudiantes pueden apuntar su dispositivo hacia monumentos y recibir información sobre su historia, personajes importantes y eventos que ocurrieron en ese lugar.\n",
      "\n",
      "3. **Simulaciones Científicas:**\n",
      "   - En el área de ciencias, los estudiantes pueden realizar experimentos virtuales. Por ejemplo, pueden observar el ciclo del agua superpuesto en un entorno real, permitiendo ver cómo se relacionan los procesos naturales con su entorno inmediato.\n",
      "\n",
      "4. **Arte y Cultura:**\n",
      "   - Al escanear obras de arte en un museo o en libros de arte, los estudiantes pueden acceder a detalles sobre la técnica utilizada, la biografía del artista y el contexto histórico de la obra, enriqueciendo su comprensión y apreciación del arte.\n",
      "\n",
      "5. **Juegos Educativos:**\n",
      "   - La aplicación incluye juegos de preguntas y respuestas que se activan en diferentes ubicaciones. Por ejemplo, al visitar un parque, los estudiantes pueden responder preguntas sobre la flora y fauna local, obteniendo recompensas virtuales por sus conocimientos.\n",
      "\n",
      "6. **Colaboración y Proyectos:**\n",
      "   - Los estudiantes pueden trabajar en proyectos grupales utilizando la aplicación. Pueden crear su propio contenido de RA, como presentaciones interactivas sobre un tema específico, que luego pueden compartir con sus compañeros.\n",
      "\n",
      "7. **Seguimiento del Progreso:**\n",
      "   - La aplicación incluye un sistema de seguimiento que permite a los docentes monitorear el progreso de los estudiantes, identificar áreas de mejora y personalizar el aprendizaje según las necesidades individuales.\n",
      "\n",
      "**Beneficios:**\n",
      "- **Aprendizaje Activo:** Fomenta un aprendizaje más activo y participativo, donde los estudiantes son protagonistas de su proceso educativo.\n",
      "- **Contextualización:** Ayuda a los estudiantes a relacionar la teoría con la práctica, mejorando la retención de información.\n",
      "- **Motivación:** La interactividad y el uso de tecnología moderna aumentan la motivación y el interés por aprender.\n",
      "\n",
      "**Implementación:**\n",
      "\"ExplorAR\" puede ser implementada en aulas de escuelas primarias y secundarias, así como en programas de educación informal, como museos y centros de ciencia, para ofrecer experiencias educativas enriquecedoras y memorables.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from operator import itemgetter\n",
    "\n",
    "# 1) LLM (usa tu OPENAI_API_KEY en el entorno)\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5)\n",
    "to_str = StrOutputParser()\n",
    "\n",
    "# 2) Paso 1: explicar brevemente el concepto de {tema}\n",
    "primer_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Explica brevemente el concepto de {tema}.\"\n",
    ")\n",
    "primer_paso = primer_prompt | llm | to_str\n",
    "# `primer_paso` produce un string, por ejemplo: \"La realidad aumentada es ...\"\n",
    "\n",
    "# 3) Paso 2: proponer una aplicación educativa usando la salida del paso 1 como {concepto}\n",
    "segundo_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Propón una aplicación educativa del siguiente concepto: {concepto}.\"\n",
    ")\n",
    "segundo_paso = segundo_prompt | llm | to_str\n",
    "\n",
    "# 4) Encadenar: mapear la entrada {tema} al primer paso, y su salida a {concepto} del segundo\n",
    "cadena_secuencial = {\"concepto\": primer_paso} | segundo_paso\n",
    "\n",
    "# 5) Ejecutar la cadena completa\n",
    "resultado = cadena_secuencial.invoke({\"tema\": \"realidad aumentada\"})\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf949db6",
   "metadata": {},
   "source": [
    "### Explicación\n",
    "- **cadena_secuencial:** permite conectar varias cadenas; la salida de una se convierte en la entrada de la siguiente.\n",
    "- En este caso, el modelo primero explica el tema y luego sugiere una aplicación educativa.\n",
    "\n",
    "Este tipo de flujo es ideal para generar contenido didáctico o ideas para proyectos en clase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0483d0",
   "metadata": {},
   "source": [
    "## 5️⃣ Ejemplo 3: Añadir memoria a la conversación\n",
    "LangChain incluye módulos de **memoria** para mantener contexto entre múltiples interacciones. Esto permite simular conversaciones educativas más naturales, donde el modelo recuerda temas previos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d363f018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Hola! ¿En qué puedo ayudarte hoy con respecto a la informática?\n",
      "Claro, aquí tienes algunas ideas sobre cómo introducir la inteligencia artificial (IA) a tus estudiantes:\n",
      "\n",
      "1. **Conceptos Básicos**: Comienza explicando qué es la IA, sus tipos (IA débil y fuerte) y sus aplicaciones en la vida cotidiana (asistentes virtuales, recomendaciones, etc.).\n",
      "\n",
      "2. **Historia de la IA**: Proporciona un breve recorrido histórico sobre el desarrollo de la IA, mencionando hitos importantes y figuras clave.\n",
      "\n",
      "3. **Ejemplos Prácticos**: Muestra ejemplos de IA en acción, como chatbots, sistemas de recomendación (Netflix, Spotify) y reconocimiento de imágenes.\n",
      "\n",
      "4. **Proyectos Prácticos**: Diseña proyectos simples donde los estudiantes puedan experimentar con herramientas de IA, como crear un chatbot básico usando plataformas como Dialogflow o utilizar TensorFlow para proyectos de aprendizaje automático.\n",
      "\n",
      "5. **Ética en IA**: Introduce discusiones sobre la ética en la IA, como sesgos en algoritmos, privacidad y el impacto en el empleo.\n",
      "\n",
      "6. **Recursos y Herramientas**: Proporciona recursos en línea, como cursos en plataformas como Coursera o edX, y herramientas de programación como Python y bibliotecas de IA (scikit-learn, Keras).\n",
      "\n",
      "7. **Futuros Desarrollos**: Habla sobre las tendencias futuras en IA y cómo podrían impactar diversas industrias.\n",
      "\n",
      "Recuerda adaptar el contenido al nivel de tus estudiantes y fomentar la curiosidad y el pensamiento crítico. ¡Buena suerte!\n",
      "Aquí tienes algunos ejemplos prácticos que puedes utilizar en clase para enseñar sobre inteligencia artificial:\n",
      "\n",
      "1. **Chatbots**:\n",
      "   - **Actividad**: Utiliza plataformas como Chatbot.com o Dialogflow para crear un chatbot simple. Los estudiantes pueden diseñar un bot que responda preguntas sobre un tema específico.\n",
      "\n",
      "2. **Clasificación de Imágenes**:\n",
      "   - **Actividad**: Usa herramientas como Teachable Machine de Google, donde los estudiantes pueden entrenar un modelo para clasificar imágenes (por ejemplo, reconocer diferentes tipos de frutas).\n",
      "\n",
      "3. **Recomendaciones**:\n",
      "   - **Actividad**: Explica cómo funcionan los sistemas de recomendación. Los estudiantes pueden crear un sistema básico en Excel que sugiera películas o libros basándose en preferencias de género.\n",
      "\n",
      "4. **Detección de Sentimientos**:\n",
      "   - **Actividad**: Utiliza una biblioteca de procesamiento de lenguaje natural (como NLTK o TextBlob en Python) para analizar comentarios o reseñas y determinar si son positivos, negativos o neutrales.\n",
      "\n",
      "5. **Reconocimiento de Voz**:\n",
      "   - **Actividad**: Muestra cómo funcionan los asistentes de voz. Puedes usar herramientas como Google Speech-to-Text para que los estudiantes conviertan voz en texto.\n",
      "\n",
      "6. **Juegos con IA**:\n",
      "   - **Actividad**: Introduce juegos simples que utilizan IA, como Tic-Tac-Toe o Akinator. Discute cómo se implementan las decisiones de la IA en estos juegos.\n",
      "\n",
      "7. **Proyectos de Aprendizaje Automático**:\n",
      "   - **Actividad**: Utiliza plataformas como Google Colab para que los estudiantes experimenten con conjuntos de datos y creen modelos de aprendizaje automático simples, como la regresión lineal.\n",
      "\n",
      "8. **Simulaciones**:\n",
      "   - **Actividad**: Usa simuladores como OpenAI Gym para que los estudiantes experimenten con algoritmos de aprendizaje por refuerzo en entornos de juego.\n",
      "\n",
      "Cada una de estas actividades puede adaptarse al nivel de tus estudiantes y fomentar la participación activa y el aprendizaje práctico. ¡Espero que encuentres útiles estas ideas!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Instalar si hace falta:\n",
    "# %pip install -U langchain langchain-openai\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# LLM (requiere OPENAI_API_KEY en el entorno)\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5)\n",
    "to_str = StrOutputParser()\n",
    "\n",
    "# Prompt con hueco para el historial\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Eres un asistente educativo claro y conciso.\"),\n",
    "    MessagesPlaceholder(\"chat_history\"),      # ← aquí va la memoria\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "# Cadena base\n",
    "chain = prompt | llm | to_str\n",
    "\n",
    "# Memoria simple como lista de mensajes\n",
    "history: list = []\n",
    "\n",
    "def chat(user_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Envía un turno del usuario, usa el historial y actualiza la memoria\n",
    "    con el par (usuario, asistente).\n",
    "    \"\"\"\n",
    "    global history\n",
    "    # Ejecutar la cadena inyectando el historial actual\n",
    "    answer = chain.invoke({\"input\": user_text, \"chat_history\": history})\n",
    "    # Actualizar memoria (guardar los dos mensajes)\n",
    "    history += [HumanMessage(content=user_text), AIMessage(content=answer)]\n",
    "    return answer\n",
    "\n",
    "# --- Ejemplo de uso (tres turnos) ---\n",
    "print(chat(\"Hola, soy un profesor de informática.\"))\n",
    "print(chat(\"¿Puedes explicarme cómo introducir IA a mis estudiantes?\"))\n",
    "print(chat(\"¿Qué ejemplos prácticos puedo usar en la clase?\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a79423b",
   "metadata": {},
   "source": [
    "### Explicación\n",
    "- **ConversationBufferMemory:** almacena los mensajes anteriores en la conversación.\n",
    "- **ConversationChain:** combina el modelo con la memoria.\n",
    "- Esta funcionalidad es útil para tutores inteligentes o chatbots educativos que requieren continuidad en el diálogo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ba0ab9",
   "metadata": {},
   "source": [
    "## 6️⃣ Buenas prácticas con LangChain + OpenAI\n",
    "- Usa prompts **claros y estructurados**: el modelo responde mejor cuando la tarea está bien definida.\n",
    "- Controla `temperature` según la tarea: bajo (0.1–0.3) para precisión, alto (0.7–0.9) para creatividad.\n",
    "- Guarda logs o historiales si tu aplicación incluye interacción prolongada.\n",
    "- Limita la longitud de las respuestas con `max_tokens` para evitar costos o respuestas excesivas.\n",
    "- Documenta tus cadenas (`LLMChain`) para reusarlas en distintos contextos educativos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a40d49",
   "metadata": {},
   "source": [
    "## ✅ Conclusión\n",
    "Has aprendido los fundamentos de LangChain: prompts, chains, memoria y flujo secuencial. Estos conceptos son la base para desarrollar asistentes educativos, tutores personalizados o sistemas de generación de contenido en el aula. En la próxima guía implementaremos un **asistente educativo con RAG (Retrieval-Augmented Generation)** usando tus propios materiales docentes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
